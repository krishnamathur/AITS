# -*- coding: utf-8 -*-
"""Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vnbdWzBBgNDmB2ufEDwEEMY_NSqSlnlW
"""

#importing necessary libraries

import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.cluster import KMeans
import sklearn.metrics as sm
 
import pandas as pd
import numpy as np
# %matplotlib inline

# importing iris dataset
iris = datasets.load_iris()

#creating list to store f1-score and accuracy
f1_score =[]
accuracy=[]
model =['KNN','Hierarchical','DBSCAN']

# Store the inputs as a Pandas Dataframe and set the column names
x = pd.DataFrame(iris.data)
x.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']
 
y = pd.DataFrame(iris.target)
y.columns = ['Targets']

print(x.head())

# Set the size of the plot
plt.figure(figsize=(14,7))
 
# Create a colormap
colormap = np.array(['red', 'lime', 'black'])
 
# Plot Sepal
plt.subplot(1, 2, 1)
plt.scatter(x.Sepal_Length, x.Sepal_Width, c=colormap[y.Targets], s=40)
plt.xlabel("length")
plt.ylabel("width")
plt.title('Sepal')
 
plt.subplot(1, 2, 2)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)
plt.xlabel("length")
plt.ylabel("width")
plt.title('Petal')

# K Means Cluster
kmodel = KMeans(n_clusters=3,random_state=10)
kmodel.fit(x)

# This is what KMeans thought
kmodel.labels_

# View the results
# Set the size of the plot
plt.figure(figsize=(14,7))
 
# Create a colormap
colormap = np.array(['red', 'lime', 'black'])
 
# Plot the Original Classifications
plt.subplot(1, 2, 1)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)
plt.title('Real Classification')
 
# Plot the Models Classifications
plt.subplot(1, 2, 2)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[kmodel.labels_], s=40)
plt.title('K Mean Classification')

# Getting accuracy
print(sm.accuracy_score(y, kmodel.labels_))
accuracy.append(sm.accuracy_score(y, kmodel.labels_))

# getting f1_score
print(sm.f1_score(y,kmodel.labels_,average='weighted'))
f1_score.append(sm.f1_score(y,kmodel.labels_,average='weighted'))

"""# **Hierarchical clustering**"""

import scipy
from scipy.cluster.hierarchy import dendrogram,linkage
from scipy.cluster.hierarchy import fcluster
from scipy.cluster.hierarchy import cophenet
from scipy.spatial.distance import pdist
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import scale

from pylab import rcParams
import seaborn as sb

np.set_printoptions(precision=4,suppress=True)
rcParams["figure.figsize"] =10,5
sb.set_style("whitegrid")

#scale the data
data = scale(iris.data)
target = pd.DataFrame(iris.target)
variable_names = iris.feature_names

z = linkage(data,"ward")

#generate dendrogram
dendrogram(z,truncate_mode= "lastp", p =12, leaf_rotation=45,leaf_font_size=15, show_contracted=True)
plt.title("Truncated Hierachial Clustering Dendrogram")
plt.xlabel("Cluster Size")
plt.ylabel("Distance")
#divide the cluster
plt.axhline(y=15)
plt.axhline(5)
plt.axhline(10)
plt.show()

#based on the dendrogram we have two clusetes 
k =3 
#build the model
HClustering = AgglomerativeClustering(n_clusters=k , affinity="euclidean",linkage="average")
#fit the model on the dataset
HClustering.fit(data)

# Plot the Original Classifications
plt.subplot(1, 2, 1)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)
plt.title('Real Classification')
 
# Plot the Models Classifications
plt.subplot(1, 2, 2)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[HClustering.labels_], s=40)
plt.title('Hierarchical Classification')

#accuracy of the model
print(sm.accuracy_score(target,HClustering.labels_))
accuracy.append(sm.accuracy_score(target,HClustering.labels_))

#getting f1_score
print(sm.f1_score(target,HClustering.labels_,average='weighted'))
f1_score.append(sm.f1_score(target,HClustering.labels_,average='weighted'))

"""# DBSCAN"""

from sklearn.cluster import DBSCAN
from collections import  Counter
# %matplotlib inline
rcParams['figure.figsize']=10,7
sb.set_style('whitegrid')

dbmodel = DBSCAN(eps = 0.8, min_samples=15).fit(x)

# getting the outliners

outliners_df = pd.DataFrame(x)

print(Counter(dbmodel.labels_))

print(outliners_df[dbmodel.labels_==-1])

# Plot the Original Classifications
plt.subplot(1, 2, 1)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)
plt.title('Real Classification')
 
# Plot the Models Classifications
plt.subplot(1, 2, 2)
plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[dbmodel.labels_], s=40)
plt.title('dbmodel Classification')

#getting accuracy
print(sm.accuracy_score(y,dbmodel.labels_))
accuracy.append(sm.accuracy_score(y,dbmodel.labels_))

#getting f1_score
print(sm.f1_score(y,dbmodel.labels_,average='weighted'))
f1_score.append(sm.f1_score(y,dbmodel.labels_,average='weighted'))

#plotting the graph to compare accuracy
print(accuracy)
plt.xlabel("models")
plt.ylabel("accuracy")
plt.title("Accuracy comparision")
plt.plot(model,accuracy)

#plotting the graph to compare f1_score
print(f1_score)
plt.xlabel("models")
plt.ylabel("F1-Score")
plt.title("F1-Score comparision")
plt.plot(model,f1_score)